Encrypted Google Docs: is an "extension", much like encrypted gmail.
    The middle way is to say, today all there is is giving up user
    privacy or using an extension; our proposal is a different plan
    that gets you the functionality which doesn't give up privacy.
    Yes it is true that we're not allowing unrestricted modification
    of existing functionality.  For extensions like encrypted gdocs,
    where the functionality is like adding encryption, we show a way
    to do them as regular web pages. (footnote: with an extension,
    you can force pages to... but that's not our use case)

UI for **clearance** modification (for extensions and mash-ups)
    asshole reviewer: what you're describing is defense in depth, and defense in depth sucks (it is admitting "I don't know what to do about this problem").  The user is in charge about deciding if they're worried about X.  If you don't like covert channels you can deny yourself functionality.  Alternately, it makes people think they should be more scared of covert channels then they are.
    Deian: but you're STILL not giving Mint the PASSWORD!!
    - What's the default policy for clearance?  A certain
      kind of systems reviewer will say, "You guys wrote a paper about richer
      functionality in a safe way, but then you told me shut your system off
      by default because users might not trust it."  (Encrypted Google Docs needs
      to be fixed properly). The path of greatest probability of success is
      to not fully take on this problem.  One approachs is to say if there
      are covert channels, relaxing SOP is dangerous (full stop).  Do we talk about
      clearance?  If we talk about clearance as a robust way of dealing with this,
      we need to carefully consider how the clearance is setup for each app.
      I don't want to get reamed by someone who figures out there's a risk we
      haven't dealt with.  We could say in abstract, say clearance is useful
      for some applications, such as the third party mashup; relax SOP, covert
      channels, this is dangerous. Clearance seems generally useful, however
      it comes at the cost of limiting flexibility.

        I think we can remove clearance from the system description.
        Lock it down; for 3rd party mashup, if there are covert channels,
        we make them worse, it is no worse than giving the password to Mint.com.
        Additional point which is CSRF and clearance.

Strengthen/weaken SOP is someting motiv-example.tex should bring
back.

Trying to think of a FAQ:
    1. Is your design backwards compatible?
    2. Why is it so fast?
    3. What about covert channels?
    4. How does this interact with CSP, etc.?
    6. I don't think developers can actually program an IFC system; I think requiring requiring the user to manipulate these policies is unreasonable.
    7. Why does your design work? How do I know it's OK?
       We shoudl cite ifc-inside paper (anonymous) saying that we have
       a formal model and security proofs
    8. What's new?

[DONE] switch back to USENIX style rather than freaky IEEE proc

we definitely need to state explicitly (possibly even in the intro?)
that our design doesn't break legacy pages/scripts (true, yes?ds: yes), and
explicitly explain why this is the case in the design section.

can Deian or EZ please convert the handwritten app figures into
computer-drawn (i.e., straight lines, typeset text) ones? Thanks!

overall, "tab" depiction in figures won't be understood as "implying
DOM" by OSDI reviewers; need to draw DOM explicitly within an origin's
frame (e.g., as a rectangle within the frame)

related work: i think that some of the fine grained ifc systems can be
used to more easily deal with phishing attacks... (maybe)

in the untrusted library scenario: it's important to not only raise
the current label, but also lower the clearance to ensure that the tcb
code in the worker can always access the DOM.

one more pretty relevant piece of related work:

(DONE:Ale!)
Embassies: Radically Refactoring the Web (Howell et al., NSDI 2013)
Broadly speaking, takes on confining malicious code supplied by web
servers within the browser. Pretty different than what we're doing in
design, but not unrelated in end-to-end goal. Also a *very* impressive
piece of work (won best paper).

THINGS WE ARE NOT GOING TO DO
-----------------------------

- DOM integrity for extensions: we AXED this, the proposal is very similar
  to Chrome's manifests as well what Script Police did.  It's an interesting
  problem, but it ends up boiling down to being a DAC, as when you give an
  extension the integrity privilege, it is not difficult to imagine (1)
  code injection attacks, (2) bugs in the page where injected DOM structures
  can induce bad things from happening, (3) phishing, etc. When giving the
  integrity basically results in free reign, you have a DAC, and this is not
  a good situation to be in (you don't need a complicated MAC in that case.)
  Another plus; axing this means we get to avoid talking about integrity entirely.
  (One other note: our proposed semantics could result in privilege escalation
  when a compartment with a DOM has extra privileges.)  We also don't have
  to talk about the DOM access label.
